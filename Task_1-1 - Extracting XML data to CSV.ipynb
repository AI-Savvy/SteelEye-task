{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1cf94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Importing necessary Libraries\n",
    "\n",
    "import boto\n",
    "import boto.s3.connection\n",
    "import xml.etree.ElementTree as et\n",
    "import pandas as pd\n",
    "import os\n",
    "# import logging\n",
    "\n",
    "access_key = ''\n",
    "secret_key = ''\n",
    "\n",
    "#S3 connection establish\n",
    "conn = boto.connect_s3(aws_access_key_id = '',\n",
    "                      aws_secret_access_key = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b86a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Check existing buckets\n",
    "for bucket in conn.get_all_buckets():\n",
    "    print(f\"Bucket name and date: {bucket.name}\\t{bucket.creation_date}\")\n",
    "    \n",
    "\n",
    "# Creating bucket\n",
    "bucket_1 = conn.create_bucket('')\n",
    "\n",
    "\n",
    "# getting bucket object\n",
    "bucket_2 = conn.get_bucket('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafe4c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Files/DLTINS_20210118_01of01.xml\n",
      "DataFrame shape: (1387, 6)\n",
      "Files/DLTINS_20210118_01of01.xml - data extraction complete...\n",
      "\n",
      "2. Files/DLTINS_20210117_01of01.xml\n",
      "DataFrame shape: (141381, 6)\n",
      "Files/DLTINS_20210117_01of01.xml - data extraction complete...\n",
      "\n",
      "3. Files/DLTINS_20210119_01of02.xml\n",
      "DataFrame shape: (500000, 6)\n",
      "Files/DLTINS_20210119_01of02.xml - data extraction complete...\n",
      "\n",
      "4. Files/DLTINS_20210119_02of02.xml\n",
      "DataFrame shape: (350982, 6)\n",
      "Files/DLTINS_20210119_02of02.xml - data extraction complete...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Assigning XML file path\n",
    "path = 'Files/'\n",
    "\n",
    "# Adding header names\n",
    "headers = ['Id', 'FullNm', 'ClssfctnTp', 'NtnlCcy', 'CmmdtyDerivInd', 'Issr']\n",
    "count = 1\n",
    "\n",
    "'''\n",
    "1. Going through all .xml files in the system path folder - src/Files/\n",
    "2. Using XML parser\n",
    "3. Extracting necessary fields using root.iter() \n",
    "4. Extracting text from child node xml blocks\n",
    "5. Looping through evey parent block\n",
    "6. Concatenating 2 different DataFrames\n",
    "7. Saving data to CSV with append option enabled\n",
    "'''\n",
    "\n",
    "for files in os.listdir(path):\n",
    "    if not files.endswith('.xml'):\n",
    "        continue\n",
    "        \n",
    "    files = os.path.join(path, files)\n",
    "    print(f'{count}. {files}')\n",
    "    \n",
    "    # Parsing XML file\n",
    "    tree = et.parse(files)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Creating row attribute\n",
    "    rows_1 = []\n",
    "    \n",
    "    # looping though all 'FinInstrmGnlAttrbts' parent blocks to extract data from child tags for our columns(tag, attrib)\n",
    "    for element in root.iter(tag= '{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}FinInstrmGnlAttrbts'):\n",
    "        Id = element[0].text\n",
    "        FullNm = element[1].text\n",
    "        ClssfctnTp = element[3].text\n",
    "        NtnlCcy = element[4].text\n",
    "        CmmdtyDerivInd = element[5].text\n",
    "        \n",
    "        # appending values to dictionart\n",
    "        rows_1.append({\"Id\" : Id,\n",
    "                       \"FullNm\" : FullNm,\n",
    "                       \"ClssfctnTp\": ClssfctnTp,\n",
    "                       \"NtnlCcy\" : NtnlCcy,\n",
    "                       \"CmmdtyDerivInd\" : CmmdtyDerivInd\n",
    "                    })\n",
    "        \n",
    "    # Creating pandas data frame to store values\n",
    "    df_1 = pd.DataFrame(rows_1)\n",
    "    \n",
    "    \n",
    "    rows_2 = []\n",
    "    \n",
    "    # looping through 'Issr' attribute\n",
    "    for value in root.iter(tag='{urn:iso:std:iso:20022:tech:xsd:auth.036.001.02}Issr'):\n",
    "        Issr = value.text\n",
    "        \n",
    "        # appending values to dictionart\n",
    "        rows_2.append({\"Issr\" : Issr})\n",
    "        \n",
    "        \n",
    "    # Creating pandas data frame to store values\n",
    "    df_2 = pd.DataFrame(rows_2)\n",
    "    \n",
    "    # Concatenating 2 different DataFrames\n",
    "    df = pd.concat([df_1, df_2], axis=1)\n",
    "    \n",
    "    # printing dataframe shape\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    # Printing status message per file\n",
    "    print(f\"{files} - data extraction complete...\\n\")\n",
    "    count += 1\n",
    "    \n",
    "    # Saving data to Excel CSV format\n",
    "    df.to_csv('Output/extracted.csv', mode='a', index=False, header=headers)\n",
    "\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c6dbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/m6hkm8w53n9d8ws5s0jvbhd40000gn/T/ipykernel_18099/1780491398.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv('Output/extracted.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(993750, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing duplicated rows\n",
    "dataset = pd.read_csv('Output/extracted.csv')\n",
    "dataset = dataset.drop(1387)\n",
    "dataset = dataset.drop(141381)\n",
    "dataset = dataset.drop(500000)\n",
    "\n",
    "# verifying duplicate rows removed by checking the shape of our dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06d26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('Output/Final.csv', mode='a', index=False, header=headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
